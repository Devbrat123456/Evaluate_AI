<%- include('../includes/header')%>

  <div class="avatar-container row" >
      <div class="col-md-6" style="overflow:hidden">
          <div class="threeContainer" id="threeContainer" >

         </div>
      </div>
      <div class="col-md-6 whatsapp-container">

    <div class="whatsapp-chat-container">
        <div class="chat-header">
            <div class="header-left">
                <div class="user-info">

                    <div class="avatar"></div>

                    <div class="user-details">

                        <h2>John Doe</h2>

                        <span class="online-status">online</span>

                    </div>
                </div>
            </div>
        </div>



    <div class="chat-messages">


        <div class="message received">

            <div class="message-content">

                <p>Hey! How are you?</p>

                <span class="timestamp">10:30 AM</span>

            </div>

        </div>


        <!-- Sent Message -->

        <div class="message sent">

            <div class="message-content">

                <p>I'm good, thanks! How about you?</p>
                 <div class="words" contenteditable>
                         <p id="p"></p>
                 </div>

                <span class="timestamp">10:31 AM</span>

                 <audio id="audioCapture"></audio>

                <div class="status-indicator">

                    <i class="fas fa-check-double"></i>

                </div>

            </div>

        </div>

    </div>


    <!-- Chat Input -->

    <div class="chat-input">

        <button class="input-icon"><i class="fas fa-paperclip"></i></button>

        <button class="input-icon"><i class="far fa-smile"></i></button>

        <input type="text" placeholder="Type a message">
         <button id="startBtn" onclick="takingInputFromUser()">Start Listening</button>
    <button id="stopRecording" >Stop Listening</button>
   
        <button class="send-button"><i class="fas fa-microphone"></i></button>

    </div>

</div>
    </div>
</div>

   
    <script type="module"  src="/assets/js/gsap.min.js"></script>
 <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
    <script type="module" defer src="/assets/utils/main.js"></script>
  
  <script src="/socket.io/socket.io.js"></script>.

  


     <script>

        document.getElementById("startBtn").addEventListener("click", () => {
         
           takingInputFromUser();
        });

       
       const speechToText= async (pathforAudioFile)=>{

          const response = await fetch(pathforAudioFile);
        const audioBlob = await response.blob(); 
        const audioFile = new File([audioBlob], "audio.wav", { type: "audio/wav" }); 

        const formData = new FormData();
        // formData.append("audio", audioFile);
        formData.append("mukul", "good");

     try {
        const response = await fetch("/ChatBox/speechToText", {
            method: "POST",
            body: {
                'name':'mukul',
            },
            headers: {
                "X-CSRF-Token": $('meta[name="csrf-token"]').attr('content')
            },
            credentials: "same-origin" 
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.message || "Upload failed");
        }

        const data = await response.json();
        console.log("Success:", data);
    } catch (error) {
        messagePop(error.message, 'error');
    }
 }

 // var socket = new io.Socket();
   var socket = io();

        // connection with server
        // socket.on('connect', function () {
        //     console.log('Connected to Server');
        //      // takingInputFromUser();
        // });
        // console.log(socket);

// socket.connect(window.location.origin); 
  var mediaRecorder;
     const takingInputFromUser = async()=>{
  var audioChunks = [];

         var constraints = { audio: true, video: false };
        navigator.mediaDevices.getUserMedia(constraints).then(function (stream)
        {

              var audio = document.getElementById('audioCapture');
              //   audio.srcObject = stream;
              //   audio.play();
              mediaRecorder = new MediaRecorder(stream);
              mediaRecorder.start();

                mediaRecorder.ondataavailable = function (event) {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
              };

 // const reader = new FileReader();
        mediaRecorder.onstop = function () {
            // Create a Blob from chunks
            var audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            var audioUrl = URL.createObjectURL(audioBlob);

            // var recordedAudio = document.createElement('audio');
            // recordedAudio.controls = true;
            // recordedAudio.src = audioUrl;
            // document.getElementById('p').appendChild(recordedAudio);

            // const blob = new Blob(audioChunks, { type: "audio/ogg; codecs=opus" });
            // const audioURL = window.URL.createObjectURL(blob)
            // "audio" below is a DOM object
            audio.src = audioUrl;
            // console.log(audioUrl);
              audio.play();
//               var reader = new FileReader();
// //Passa o BLOB como parametro
// reader.readAsText(audioBlob);
// //Pode visualizar os dados gerados em texto
// console.log(reader.result,reader);
              speechToText(audioUrl);


            
            // Send the recorded audio to a server
           
        };

         document.getElementById('stopRecording').addEventListener('click', function () {
            mediaRecorder.stop();
            console.log("Recording stopped...");
        });
        }).catch(function (err)
        {
            console.log(err);
        });
      

     }



    //   if (!('webkitSpeechRecognition' in window)) {
    //     alert("Your browser doesn't support the Web Speech API. Please use Chrome or Edge.");
    // } else {
    //     // Create a new instance of SpeechRecognition
    //     const recognition = new webkitSpeechRecognition();

    //     // Set properties
    //     recognition.continuous = false; // Capture only one result
    //     recognition.interimResults = false; // Get the final result, not partial results
    //     recognition.lang = 'en-US'; // Set the language to English

    //     // Start button click event
    //     document.getElementById('startBtn').onclick = () => {
    //         recognition.start(); // Start listening
    //     };

    //     // Handle the result when speech is detected
    //     recognition.onresult = (event) => {
    //         const transcript = event.results[0][0].transcript; // Get the speech result
    //         // document.getElementById('result').innerText = `You said: ${transcript}`;
    //         console.log(`You said: ${transcript}`);
    //     };

    //     // Handle any errors
    //     recognition.onerror = (event) => {
    //         console.error('Speech recognition error:', event.error);
    //     };

    //     // Log when the speech recognition service starts or ends
    //     recognition.onstart = () => {
    //         console.log('Speech recognition started');
    //     };
    //     recognition.onend = () => {
    //         console.log('Speech recognition ended');
    //     };
    // }
    

    </script>

<%- include('../includes/footer') %>